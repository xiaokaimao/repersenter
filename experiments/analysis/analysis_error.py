"""
åŸºäºShapleyå€¼çš„é”™è¯¯æ£€æµ‹å’Œæ•°æ®è´¨é‡åˆ†æ
ç”¨äºè¯†åˆ«æ ‡ç­¾å™ªå£°ã€å¼‚å¸¸æ ·æœ¬å’Œä½è´¨é‡æ•°æ®
"""
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.manifold import TSNE
import pandas as pd

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
import config.settings as settings

def load_shapley_data(experiment_type='resnet'):
    """åŠ è½½Shapleyå€¼æ•°æ®"""
    config = settings.CORE_SET_EXPERIMENT_CONFIG[experiment_type]
    
    if experiment_type == 'transformer':
        model_name_safe = config['model_name'].replace('/', '_')
        shapley_file_name = f"shapley_vectors_{config['dataset_name']}_{model_name_safe}_noise_{config.get('label_noise_rate', 0.0)}.pt"
    else:
        shapley_file_name = f"shapley_vectors_{config['dataset_name']}_{config['model_name']}_noise_{config.get('label_noise_rate', 0.0)}.pt"
    
    load_path = os.path.join(settings.RESULTS_DIR, shapley_file_name)
    
    if not os.path.exists(load_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°Shapleyæ–‡ä»¶: {load_path}")
    
    return torch.load(load_path, map_location='cpu')


def calculate_original_label_contribution(shapley_vectors, original_labels):
    """
    è®¡ç®—æ¯ä¸ªæ ·æœ¬å¯¹å…¶åŸå§‹çœŸå®æ ‡ç­¾çš„è´¡çŒ®
    
    Args:
        shapley_vectors: Shapleyå€¼çŸ©é˜µ (n_samples, n_classes)
        original_labels: åŸå§‹çœŸå®æ ‡ç­¾
    
    Returns:
        numpy.array: æ¯ä¸ªæ ·æœ¬å¯¹å…¶åŸå§‹æ ‡ç­¾çš„è´¡çŒ®åˆ†æ•°
    """
    # æå–æ¯ä¸ªæ ·æœ¬å¯¹å…¶åŸå§‹çœŸå®æ ‡ç­¾çš„Shapleyå€¼
    indices = torch.arange(len(original_labels))
    contribution_scores = shapley_vectors[indices, original_labels].numpy()
    return contribution_scores


def detect_mislabeled_samples(shapley_data, threshold=0.0):
    """
    æ£€æµ‹å¯èƒ½çš„é”™è¯¯æ ‡ç­¾æ ·æœ¬åŸºäºå¯¹åŸå§‹æ ‡ç­¾çš„è´¡çŒ®
    
    Args:
        shapley_data: åŒ…å«Shapleyå€¼å’Œæ ‡ç­¾ä¿¡æ¯çš„æ•°æ®
        threshold: è´¡çŒ®é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„æ ·æœ¬è¢«è®¤ä¸ºæ˜¯å¯ç–‘çš„ï¼ˆé»˜è®¤0.0ï¼‰
    
    Returns:
        dict: åŒ…å«æ£€æµ‹ç»“æœçš„å­—å…¸
    """
    shapley_vectors = shapley_data['shapley_vectors']
    noisy_labels = shapley_data['noisy_labels']
    original_labels = shapley_data.get('original_labels', noisy_labels)
    flipped_indices = shapley_data.get('flipped_indices', [])
    
    # è®¡ç®—æ¯ä¸ªæ ·æœ¬å¯¹å…¶åŸå§‹çœŸå®æ ‡ç­¾çš„è´¡çŒ®
    contribution_scores = calculate_original_label_contribution(shapley_vectors, original_labels)
    
    # è¯†åˆ«è´Ÿè´¡çŒ®æ ·æœ¬ï¼ˆå¯¹åŸå§‹æ ‡ç­¾æœ‰å®³çš„æ ·æœ¬ï¼‰
    suspicious_indices = np.where(contribution_scores < threshold)[0]
    
    # åŸºæœ¬ç»Ÿè®¡
    detection_results = {
        'suspicious_indices': suspicious_indices,
        'contribution_scores': contribution_scores,
        'threshold': threshold,
        'num_suspicious': len(suspicious_indices)
    }
    
    # åˆ†ç»„ç»Ÿè®¡
    all_indices = np.arange(len(original_labels))
    correct_indices = np.setdiff1d(all_indices, flipped_indices)
    
    if len(flipped_indices) > 0:
        flipped_scores = contribution_scores[flipped_indices]
        correct_scores = contribution_scores[correct_indices]
        
        detection_results.update({
            'flipped_scores_mean': np.mean(flipped_scores),
            'flipped_scores_std': np.std(flipped_scores),
            'correct_scores_mean': np.mean(correct_scores),
            'correct_scores_std': np.std(correct_scores),
        })
        
        # è®¡ç®—æ£€æµ‹æ€§èƒ½
        # ç¡®ä¿ç±»å‹ä¸€è‡´ï¼Œè½¬æ¢ä¸ºæ•´æ•°é›†åˆ
        true_flipped = set(int(x) for x in flipped_indices)
        detected_suspicious = set(int(x) for x in suspicious_indices)
        
        true_positives = len(true_flipped & detected_suspicious)
        false_positives = len(detected_suspicious - true_flipped)
        false_negatives = len(true_flipped - detected_suspicious)
        
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        detection_results.update({
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'true_positives': true_positives,
            'false_positives': false_positives,
            'false_negatives': false_negatives,
            'actual_flipped_count': len(flipped_indices)
        })
    
    return detection_results


def visualize_detection_results(shapley_data, save_dir):
    """
    å¯è§†åŒ–é”™è¯¯æ£€æµ‹ç»“æœï¼ˆåŸºäºå¯¹åŸå§‹æ ‡ç­¾çš„è´¡çŒ®ï¼‰
    """
    shapley_vectors = shapley_data['shapley_vectors']
    original_labels = shapley_data.get('original_labels', shapley_data['noisy_labels'])
    flipped_indices = shapley_data.get('flipped_indices', [])
    
    # è®¡ç®—å¯¹åŸå§‹æ ‡ç­¾çš„è´¡çŒ®
    contribution_scores = calculate_original_label_contribution(shapley_vectors, original_labels)
    
    # åˆ†ç»„
    all_indices = np.arange(len(original_labels))
    correct_indices = np.setdiff1d(all_indices, flipped_indices)
    
    flipped_scores = contribution_scores[flipped_indices]
    correct_scores = contribution_scores[correct_indices]
    
    plt.figure(figsize=(12, 8))
    
    # ç»˜åˆ¶åˆ†å¸ƒç›´æ–¹å›¾
    plt.hist(correct_scores, bins=50, density=True, alpha=0.7, 
             label=f'æ­£ç¡®æ ‡ç­¾æ ·æœ¬ (å‡å€¼: {np.mean(correct_scores):.3f})', color='green')
    plt.hist(flipped_scores, bins=20, density=True, alpha=0.8, 
             label=f'é”™è¯¯æ ‡ç­¾æ ·æœ¬ (å‡å€¼: {np.mean(flipped_scores):.3f})', color='red')
    
    # æ·»åŠ å†³ç­–è¾¹ç•Œ
    plt.axvline(x=0, color='black', linestyle='--', linewidth=2, label='å†³ç­–è¾¹ç•Œ (x=0)')
    
    plt.title('å¯¹åŸå§‹çœŸå®æ ‡ç­¾çš„Shapleyè´¡çŒ®åˆ†å¸ƒ', fontsize=16, fontweight='bold')
    plt.xlabel('Shapleyè´¡çŒ®å€¼', fontsize=12)
    plt.ylabel('å¯†åº¦', fontsize=12)
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, 'contribution_distribution.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return save_path


def generate_analysis_report(detection_results, experiment_type, save_dir):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆåŸºäºåŸå§‹æ ‡ç­¾è´¡çŒ®æ–¹æ³•ï¼‰"""
    report_lines = []
    report_lines.append("# Shapleyå€¼é”™è¯¯æ£€æµ‹åˆ†ææŠ¥å‘Š\n")
    report_lines.append(f"å®éªŒç±»å‹: {experiment_type.upper()}\n")
    report_lines.append(f"åˆ†ææ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    
    report_lines.append("## æ£€æµ‹æ–¹æ³•\n")
    report_lines.append("- **æ£€æµ‹æ–¹æ³•**: åŸå§‹æ ‡ç­¾è´¡çŒ®æ³•\n")
    report_lines.append("- **åŸç†**: è®¡ç®—æ¯ä¸ªæ ·æœ¬å¯¹å…¶åŸå§‹çœŸå®æ ‡ç­¾çš„Shapleyè´¡çŒ®\n")
    report_lines.append("- **é˜ˆå€¼**: è´¡çŒ®å€¼ < 0 çš„æ ·æœ¬è¢«æ ‡è®°ä¸ºå¯ç–‘\n\n")
    
    report_lines.append("## æ£€æµ‹ç»“æœæ¦‚è¿°\n")
    total_samples = len(detection_results['contribution_scores'])
    report_lines.append(f"- æ€»æ ·æœ¬æ•°: {total_samples}\n")
    report_lines.append(f"- å¯ç–‘æ ·æœ¬æ•°: {detection_results['num_suspicious']}\n")
    report_lines.append(f"- å¯ç–‘æ ·æœ¬æ¯”ä¾‹: {detection_results['num_suspicious']/total_samples*100:.2f}%\n")
    report_lines.append(f"- æ£€æµ‹é˜ˆå€¼: {detection_results['threshold']:.6f}\n\n")
    
    if 'precision' in detection_results:
        report_lines.append("## æ£€æµ‹æ€§èƒ½æŒ‡æ ‡\n")
        report_lines.append(f"- ç²¾ç¡®ç‡ (Precision): {detection_results['precision']:.4f}\n")
        report_lines.append(f"- å¬å›ç‡ (Recall): {detection_results['recall']:.4f}\n")
        report_lines.append(f"- F1åˆ†æ•°: {detection_results['f1_score']:.4f}\n")
        report_lines.append(f"- çœŸæ­£ä¾‹ (TP): {detection_results['true_positives']}\n")
        report_lines.append(f"- å‡æ­£ä¾‹ (FP): {detection_results['false_positives']}\n")
        report_lines.append(f"- å‡è´Ÿä¾‹ (FN): {detection_results['false_negatives']}\n")
        report_lines.append(f"- å®é™…ç¿»è½¬æ ·æœ¬æ•°: {detection_results['actual_flipped_count']}\n\n")
    
    # è´¡çŒ®åˆ†æ•°ç»Ÿè®¡
    scores = detection_results['contribution_scores']
    report_lines.append("## åŸå§‹æ ‡ç­¾è´¡çŒ®ç»Ÿè®¡\n")
    report_lines.append(f"- å¹³å‡å€¼: {np.mean(scores):.6f}\n")
    report_lines.append(f"- æ ‡å‡†å·®: {np.std(scores):.6f}\n")
    report_lines.append(f"- æœ€å°å€¼: {np.min(scores):.6f}\n")
    report_lines.append(f"- æœ€å¤§å€¼: {np.max(scores):.6f}\n")
    report_lines.append(f"- 5%åˆ†ä½æ•°: {np.percentile(scores, 5):.6f}\n")
    report_lines.append(f"- 95%åˆ†ä½æ•°: {np.percentile(scores, 95):.6f}\n\n")
    
    # åˆ†ç»„ç»Ÿè®¡
    if 'correct_scores_mean' in detection_results:
        report_lines.append("## åˆ†ç»„ç»Ÿè®¡åˆ†æ\n")
        report_lines.append(f"- **æ­£ç¡®æ ‡ç­¾æ ·æœ¬å‡å€¼**: {detection_results['correct_scores_mean']:.6f}\n")
        report_lines.append(f"- **æ­£ç¡®æ ‡ç­¾æ ·æœ¬æ ‡å‡†å·®**: {detection_results['correct_scores_std']:.6f}\n")
        report_lines.append(f"- **é”™è¯¯æ ‡ç­¾æ ·æœ¬å‡å€¼**: {detection_results['flipped_scores_mean']:.6f}\n")
        report_lines.append(f"- **é”™è¯¯æ ‡ç­¾æ ·æœ¬æ ‡å‡†å·®**: {detection_results['flipped_scores_std']:.6f}\n\n")
        
        # æ•ˆæœéªŒè¯
        if detection_results['flipped_scores_mean'] < 0 and detection_results['correct_scores_mean'] > 0:
            report_lines.append("**âœ… éªŒè¯ç»“æœ**: é”™è¯¯æ ‡ç­¾æ ·æœ¬çš„å¹³å‡è´¡çŒ®ä¸ºè´Ÿå€¼ï¼Œæ­£ç¡®æ ‡ç­¾æ ·æœ¬ä¸ºæ­£å€¼ï¼Œç¬¦åˆç†è®ºé¢„æœŸã€‚\n\n")
        else:
            report_lines.append("**âš ï¸ æ³¨æ„**: è´¡çŒ®å€¼åˆ†å¸ƒå¯èƒ½ä¸ç†è®ºé¢„æœŸä¸ç¬¦ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æã€‚\n\n")
    
    report_lines.append("## å»ºè®®\n")
    if 'f1_score' in detection_results:
        if detection_results['f1_score'] > 0.7:
            report_lines.append("- âœ… æ£€æµ‹æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥ä¿¡ä»»æ£€æµ‹ç»“æœ\n")
        elif detection_results['f1_score'] > 0.5:
            report_lines.append("- âš ï¸ æ£€æµ‹æ€§èƒ½ä¸­ç­‰ï¼Œå»ºè®®ç»“åˆå…¶ä»–æ–¹æ³•éªŒè¯\n")
        else:
            report_lines.append("- âŒ æ£€æµ‹æ€§èƒ½è¾ƒå·®ï¼Œå»ºè®®è°ƒæ•´é˜ˆå€¼æˆ–æ–¹æ³•\n")
    
    report_lines.append("- å»ºè®®æ‰‹åŠ¨æ£€æŸ¥è´¡çŒ®åˆ†æ•°æœ€ä½çš„æ ·æœ¬\n")
    report_lines.append("- å¯ä»¥è€ƒè™‘ç§»é™¤æˆ–é‡æ–°æ ‡æ³¨æ£€æµ‹åˆ°çš„å¯ç–‘æ ·æœ¬\n")
    report_lines.append("- ç›‘æ§æ•°æ®è´¨é‡ï¼Œå®šæœŸè¿›è¡Œé”™è¯¯æ£€æµ‹åˆ†æ\n")
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(save_dir, f'analysis_report_{experiment_type}.md')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.writelines(report_lines)
    
    return report_path

def generate_comparison_report(detection_results_norm, detection_results_contrib, experiment_type, save_dir):
    """ç”Ÿæˆä¸¤ç§æ–¹æ³•çš„æ¯”è¾ƒæŠ¥å‘Š"""
    report_lines = []
    report_lines.append("# Shapleyå€¼é”™è¯¯æ£€æµ‹æ–¹æ³•æ¯”è¾ƒæŠ¥å‘Š\\n")
    report_lines.append(f"å®éªŒç±»å‹: {experiment_type.upper()}\\n")
    report_lines.append(f"åˆ†ææ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n")
    
    # æ–¹æ³•å¯¹æ¯”
    report_lines.append("## æ£€æµ‹æ–¹æ³•å¯¹æ¯”\\n")
    report_lines.append("### æ–¹æ³•1: L2èŒƒæ•°æ£€æµ‹æ³•\\n")
    report_lines.append("- **åŸç†**: ä½¿ç”¨Shapleyå‘é‡çš„L2èŒƒæ•°ä½œä¸ºæ ·æœ¬æœ‰ç”¨æ€§æŒ‡æ ‡\\n")
    report_lines.append("- **é˜ˆå€¼**: æœ€ä½5%çš„æ ·æœ¬è¢«æ ‡è®°ä¸ºå¯ç–‘\\n")
    report_lines.append(f"- **æ£€æµ‹æ ·æœ¬æ•°**: {detection_results_norm['num_suspicious']}\\n")
    
    if 'f1_score' in detection_results_norm:
        report_lines.append(f"- **ç²¾ç¡®ç‡**: {detection_results_norm['precision']:.4f}\\n")
        report_lines.append(f"- **å¬å›ç‡**: {detection_results_norm['recall']:.4f}\\n")
        report_lines.append(f"- **F1åˆ†æ•°**: {detection_results_norm['f1_score']:.4f}\\n")
    
    report_lines.append("\\n### æ–¹æ³•2: åŸå§‹æ ‡ç­¾è´¡çŒ®æ£€æµ‹æ³• (experiment.pyæ–¹æ³•)\\n")
    report_lines.append("- **åŸç†**: è®¡ç®—æ¯ä¸ªæ ·æœ¬å¯¹å…¶åŸå§‹çœŸå®æ ‡ç­¾çš„Shapleyè´¡çŒ®\\n")
    report_lines.append("- **é˜ˆå€¼**: è´¡çŒ®å€¼ < 0 çš„æ ·æœ¬è¢«æ ‡è®°ä¸ºå¯ç–‘\\n")
    report_lines.append(f"- **æ£€æµ‹æ ·æœ¬æ•°**: {detection_results_contrib['num_suspicious']}\\n")
    
    if 'f1_score' in detection_results_contrib:
        report_lines.append(f"- **ç²¾ç¡®ç‡**: {detection_results_contrib['precision']:.4f}\\n")
        report_lines.append(f"- **å¬å›ç‡**: {detection_results_contrib['recall']:.4f}\\n")
        report_lines.append(f"- **F1åˆ†æ•°**: {detection_results_contrib['f1_score']:.4f}\\n")
    
    # è´¡çŒ®åˆ†æ•°ç»Ÿè®¡
    if 'correct_scores_mean' in detection_results_contrib:
        report_lines.append("\\n## åŸå§‹æ ‡ç­¾è´¡çŒ®ç»Ÿè®¡\\n")
        report_lines.append(f"- **æ­£ç¡®æ ‡ç­¾æ ·æœ¬å‡å€¼**: {detection_results_contrib['correct_scores_mean']:.6f}\\n")
        report_lines.append(f"- **æ­£ç¡®æ ‡ç­¾æ ·æœ¬æ ‡å‡†å·®**: {detection_results_contrib['correct_scores_std']:.6f}\\n")
        report_lines.append(f"- **é”™è¯¯æ ‡ç­¾æ ·æœ¬å‡å€¼**: {detection_results_contrib['flipped_scores_mean']:.6f}\\n")
        report_lines.append(f"- **é”™è¯¯æ ‡ç­¾æ ·æœ¬æ ‡å‡†å·®**: {detection_results_contrib['flipped_scores_std']:.6f}\\n")
        
        # æ•ˆæœéªŒè¯
        if detection_results_contrib['flipped_scores_mean'] < 0 and detection_results_contrib['correct_scores_mean'] > 0:
            report_lines.append("\\n**âœ… éªŒè¯ç»“æœ**: é”™è¯¯æ ‡ç­¾æ ·æœ¬çš„å¹³å‡è´¡çŒ®ä¸ºè´Ÿå€¼ï¼Œæ­£ç¡®æ ‡ç­¾æ ·æœ¬ä¸ºæ­£å€¼ï¼Œç¬¦åˆç†è®ºé¢„æœŸã€‚\\n")
        else:
            report_lines.append("\\n**âš ï¸ æ³¨æ„**: è´¡çŒ®å€¼åˆ†å¸ƒå¯èƒ½ä¸ç†è®ºé¢„æœŸä¸ç¬¦ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æã€‚\\n")
    
    # æ–¹æ³•æ¯”è¾ƒ
    report_lines.append("\\n## æ–¹æ³•ä¼˜ç¼ºç‚¹æ¯”è¾ƒ\\n")
    report_lines.append("### L2èŒƒæ•°æ–¹æ³•\\n")
    report_lines.append("- **ä¼˜ç‚¹**: è€ƒè™‘æ ·æœ¬å¯¹æ‰€æœ‰ç±»åˆ«çš„æ•´ä½“è´¡çŒ®ï¼Œæ›´å…¨é¢\\n")
    report_lines.append("- **ç¼ºç‚¹**: éœ€è¦æ‰‹åŠ¨è®¾å®šç™¾åˆ†ä½é˜ˆå€¼ï¼Œå¯èƒ½ä¸å¤Ÿç›´è§‚\\n")
    
    report_lines.append("\\n### åŸå§‹æ ‡ç­¾è´¡çŒ®æ–¹æ³•\\n")
    report_lines.append("- **ä¼˜ç‚¹**: ç›´æ¥é’ˆå¯¹çœŸå®æ ‡ç­¾ï¼Œé€»è¾‘æ¸…æ™°ï¼Œé˜ˆå€¼è‡ªç„¶(0)\\n")
    report_lines.append("- **ç¼ºç‚¹**: ä»…è€ƒè™‘å¯¹æ­£ç¡®ç±»åˆ«çš„è´¡çŒ®ï¼Œå¯èƒ½å¿½ç•¥å…¶ä»–ä¿¡æ¯\\n")
    
    # å»ºè®®
    report_lines.append("\\n## ä½¿ç”¨å»ºè®®\\n")
    if 'f1_score' in detection_results_norm and 'f1_score' in detection_results_contrib:
        if detection_results_contrib['f1_score'] > detection_results_norm['f1_score']:
            report_lines.append("- ğŸ“Š **æ¨è**: åŸå§‹æ ‡ç­¾è´¡çŒ®æ–¹æ³•åœ¨å½“å‰æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½\\n")
        else:
            report_lines.append("- ğŸ“Š **æ¨è**: L2èŒƒæ•°æ–¹æ³•åœ¨å½“å‰æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½\\n")
    
    report_lines.append("- ğŸ’¡ **ç»“åˆä½¿ç”¨**: å¯ä»¥åŒæ—¶ä½¿ç”¨ä¸¤ç§æ–¹æ³•ï¼Œå–äº¤é›†è·å¾—é«˜ç½®ä¿¡åº¦çš„é”™è¯¯æ ·æœ¬\\n")
    report_lines.append("- ğŸ” **äººå·¥éªŒè¯**: å¯¹æ£€æµ‹åˆ°çš„å¯ç–‘æ ·æœ¬è¿›è¡Œäººå·¥å®¡æ ¸ï¼Œæé«˜å‡†ç¡®æ€§\\n")
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(save_dir, f'comparison_report_{experiment_type}.md')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.writelines(report_lines)
    
    return report_path

def run_error_analysis(experiment_type='resnet', threshold=0.0):
    """è¿è¡Œå®Œæ•´çš„é”™è¯¯åˆ†æï¼ˆåŸºäºåŸå§‹æ ‡ç­¾è´¡çŒ®æ–¹æ³•ï¼‰"""
    print(f"ğŸ” å¼€å§‹é”™è¯¯åˆ†æ: {experiment_type.upper()}")
    
    # åˆ›å»ºç»“æœç›®å½•
    save_dir = os.path.join(settings.RESULTS_DIR, f'error_analysis_{experiment_type}')
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½Shapleyå€¼æ•°æ®...")
    try:
        shapley_data = load_shapley_data(experiment_type)
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("è¯·å…ˆè¿è¡ŒShapleyå€¼è®¡ç®—è„šæœ¬ç”Ÿæˆæ•°æ®ã€‚")
        return
    
    # æ£€æµ‹é”™è¯¯æ ‡ç­¾ï¼ˆä½¿ç”¨åŸå§‹æ ‡ç­¾è´¡çŒ®æ–¹æ³•ï¼‰
    print("ğŸ•µï¸ æ£€æµ‹å¯ç–‘æ ·æœ¬ï¼ˆåŸºäºåŸå§‹æ ‡ç­¾è´¡çŒ®ï¼‰...")
    detection_results = detect_mislabeled_samples(shapley_data, threshold)
    
    # å¯è§†åŒ–æ£€æµ‹ç»“æœ
    print("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    detection_plot_path = visualize_detection_results(shapley_data, save_dir)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report_path = generate_analysis_report(detection_results, experiment_type, save_dir)
    
    # æ‰“å°ç»“æœ
    print(f"\n=== ğŸ¯ é”™è¯¯åˆ†æç»“æœ ===")
    total_samples = len(detection_results['contribution_scores'])
    print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"å¯ç–‘æ ·æœ¬æ•°: {detection_results['num_suspicious']}")
    print(f"å¯ç–‘æ ·æœ¬æ¯”ä¾‹: {detection_results['num_suspicious']/total_samples*100:.2f}%")
    
    if 'f1_score' in detection_results:
        print(f"æ£€æµ‹ç²¾ç¡®ç‡: {detection_results['precision']:.4f}")
        print(f"æ£€æµ‹å¬å›ç‡: {detection_results['recall']:.4f}")
        print(f"F1åˆ†æ•°: {detection_results['f1_score']:.4f}")
    
    # æ˜¾ç¤ºè´¡çŒ®ç»Ÿè®¡
    if 'correct_scores_mean' in detection_results:
        print(f"\n=== ğŸ“ˆ è´¡çŒ®ç»Ÿè®¡ ===")
        print(f"æ­£ç¡®æ ·æœ¬å‡å€¼: {detection_results['correct_scores_mean']:.6f}")
        print(f"é”™è¯¯æ ·æœ¬å‡å€¼: {detection_results['flipped_scores_mean']:.6f}")
        verification = "âœ… ç¬¦åˆé¢„æœŸ" if detection_results['flipped_scores_mean'] < 0 and detection_results['correct_scores_mean'] > 0 else "âš ï¸ éœ€è¦åˆ†æ"
        print(f"ç†è®ºéªŒè¯: {verification}")
    
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
    print(f"ğŸ¨ æ£€æµ‹ç»“æœå›¾: {detection_plot_path}")
    print(f"ğŸ“ åˆ†ææŠ¥å‘Š: {report_path}")
    
    return {
        'detection_results': detection_results,
        'save_dir': save_dir,
        'plots': {
            'detection': detection_plot_path
        },
        'report': report_path
    }

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="åŸºäºShapleyå€¼çš„é”™è¯¯æ£€æµ‹åˆ†æï¼ˆåŸå§‹æ ‡ç­¾è´¡çŒ®æ–¹æ³•ï¼‰")
    parser.add_argument("--type", choices=["resnet", "transformer"], 
                       default="resnet", help="å®éªŒç±»å‹")
    parser.add_argument("--threshold", type=float, default=0.0,
                       help="æ£€æµ‹é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„æ ·æœ¬è¢«è®¤ä¸ºæ˜¯å¯ç–‘çš„ (default: 0.0)")
    args = parser.parse_args()
    
    run_error_analysis(args.type, args.threshold)