"""
ç»Ÿä¸€çš„Shapleyå€¼åˆ†æå…¥å£è„šæœ¬
æ”¯æŒé”™è¯¯æ£€æµ‹ã€æ•°æ®ä¼°å€¼å’Œç»¼åˆåˆ†æ
"""
import argparse
import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from analysis_error import run_error_analysis
from data_valuation import run_data_valuation

def run_comprehensive_analysis(experiment_type='resnet', 
                             error_threshold=5.0, 
                             n_clusters=5):
    """è¿è¡Œç»¼åˆåˆ†æ"""
    print("ğŸ”¬ å¼€å§‹ç»¼åˆShapleyå€¼åˆ†æ")
    print("=" * 50)
    
    results = {}
    
    # 1. é”™è¯¯æ£€æµ‹åˆ†æ
    print("\nğŸ“ ç¬¬1æ­¥: é”™è¯¯æ£€æµ‹åˆ†æ")
    try:
        error_results = run_error_analysis(experiment_type, error_threshold)
        results['error_analysis'] = error_results
        print("âœ… é”™è¯¯æ£€æµ‹åˆ†æå®Œæˆ")
    except Exception as e:
        print(f"âŒ é”™è¯¯æ£€æµ‹åˆ†æå¤±è´¥: {e}")
        results['error_analysis'] = None
    
    # 2. æ•°æ®ä»·å€¼è¯„ä¼°
    print("\nğŸ“ ç¬¬2æ­¥: æ•°æ®ä»·å€¼è¯„ä¼°")
    try:
        valuation_results = run_data_valuation(experiment_type, n_clusters)
        results['valuation_analysis'] = valuation_results
        print("âœ… æ•°æ®ä»·å€¼è¯„ä¼°å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ•°æ®ä»·å€¼è¯„ä¼°å¤±è´¥: {e}")
        results['valuation_analysis'] = None
    
    # 3. ç”Ÿæˆç»¼åˆæ€»ç»“
    print("\nğŸ“ ç¬¬3æ­¥: ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š")
    try:
        summary_path = generate_comprehensive_summary(results, experiment_type)
        results['summary_report'] = summary_path
        print("âœ… ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    except Exception as e:
        print(f"âŒ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        results['summary_report'] = None
    
    # è¾“å‡ºç»“æœæ€»è§ˆ
    print("\n" + "=" * 50)
    print("ğŸ¯ åˆ†æå®Œæˆæ€»è§ˆ")
    print("=" * 50)
    
    if results['error_analysis']:
        error_res = results['error_analysis']['detection_results']
        print(f"ğŸ“Š é”™è¯¯æ£€æµ‹: å‘ç° {error_res['num_suspicious']} ä¸ªå¯ç–‘æ ·æœ¬")
        if 'f1_score' in error_res:
            print(f"   æ£€æµ‹æ€§èƒ½: F1={error_res['f1_score']:.3f}, Precision={error_res['precision']:.3f}, Recall={error_res['recall']:.3f}")
    
    if results['valuation_analysis']:
        val_metrics = results['valuation_analysis']['value_metrics']
        print(f"ğŸ’ æ•°æ®ä¼°å€¼: å¹³å‡ä»·å€¼ {val_metrics['l2_norm'].mean():.6f} Â± {val_metrics['l2_norm'].std():.6f}")
        print(f"   æ ·æœ¬åˆ†å¸ƒ: {len(val_metrics['l2_norm'])} ä¸ªæ ·æœ¬ï¼Œ{n_clusters} ä¸ªèšç±»")
    
    if results['summary_report']:
        print(f"ğŸ“ ç»¼åˆæŠ¥å‘Š: {results['summary_report']}")
    
    return results

def generate_comprehensive_summary(results, experiment_type):
    """ç”Ÿæˆç»¼åˆåˆ†ææ€»ç»“æŠ¥å‘Š"""
    import config.settings as settings
    import pandas as pd
    
    save_dir = os.path.join(settings.RESULTS_DIR, f'comprehensive_analysis_{experiment_type}')
    os.makedirs(save_dir, exist_ok=True)
    
    report_lines = []
    report_lines.append("# Shapleyå€¼ç»¼åˆåˆ†ææŠ¥å‘Š\n")
    report_lines.append(f"å®éªŒç±»å‹: {experiment_type.upper()}\n")
    report_lines.append(f"åˆ†ææ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    
    # æ‰§è¡Œæ¦‚è§ˆ
    report_lines.append("## åˆ†ææ‰§è¡Œæ¦‚è§ˆ\n")
    if results['error_analysis']:
        report_lines.append("- âœ… é”™è¯¯æ£€æµ‹åˆ†æ: æˆåŠŸå®Œæˆ\n")
    else:
        report_lines.append("- âŒ é”™è¯¯æ£€æµ‹åˆ†æ: æ‰§è¡Œå¤±è´¥\n")
    
    if results['valuation_analysis']:
        report_lines.append("- âœ… æ•°æ®ä»·å€¼è¯„ä¼°: æˆåŠŸå®Œæˆ\n")
    else:
        report_lines.append("- âŒ æ•°æ®ä»·å€¼è¯„ä¼°: æ‰§è¡Œå¤±è´¥\n")
    
    report_lines.append("\n")
    
    # é”™è¯¯æ£€æµ‹ç»“æœæ€»ç»“
    if results['error_analysis']:
        error_res = results['error_analysis']['detection_results']
        report_lines.append("## é”™è¯¯æ£€æµ‹åˆ†ææ€»ç»“\n")
        report_lines.append(f"- æ€»æ ·æœ¬æ•°: {len(error_res['usefulness_scores'])}\n")
        report_lines.append(f"- å¯ç–‘æ ·æœ¬æ•°: {error_res['num_suspicious']}\n")
        report_lines.append(f"- å¯ç–‘æ ·æœ¬æ¯”ä¾‹: {error_res['num_suspicious']/len(error_res['usefulness_scores'])*100:.2f}%\n")
        
        if 'f1_score' in error_res:
            report_lines.append(f"- æ£€æµ‹ç²¾ç¡®ç‡: {error_res['precision']:.4f}\n")
            report_lines.append(f"- æ£€æµ‹å¬å›ç‡: {error_res['recall']:.4f}\n")
            report_lines.append(f"- F1åˆ†æ•°: {error_res['f1_score']:.4f}\n")
        
        report_lines.append(f"- æ£€æµ‹é˜ˆå€¼: {error_res['threshold']:.6f}\n\n")
    
    # æ•°æ®ä»·å€¼è¯„ä¼°æ€»ç»“
    if results['valuation_analysis']:
        val_metrics = results['valuation_analysis']['value_metrics']
        categories = results['valuation_analysis']['categories']
        category_names = results['valuation_analysis']['category_names']
        
        report_lines.append("## æ•°æ®ä»·å€¼è¯„ä¼°æ€»ç»“\n")
        report_lines.append(f"- æ ·æœ¬æ€»æ•°: {len(val_metrics['l2_norm'])}\n")
        report_lines.append(f"- å¹³å‡ä»·å€¼: {val_metrics['l2_norm'].mean():.6f}\n")
        report_lines.append(f"- ä»·å€¼æ ‡å‡†å·®: {val_metrics['l2_norm'].std():.6f}\n")
        report_lines.append(f"- ä»·å€¼èŒƒå›´: [{val_metrics['l2_norm'].min():.6f}, {val_metrics['l2_norm'].max():.6f}]\n")
        
        report_lines.append("\n### ä»·å€¼åˆ†ç±»åˆ†å¸ƒ\n")
        total_samples = len(categories)
        for i, name in enumerate(category_names):
            count = sum(categories == i)
            percentage = count / total_samples * 100
            report_lines.append(f"- {name}: {count}ä¸ªæ ·æœ¬ ({percentage:.1f}%)\n")
        
        report_lines.append("\n")
    
    # ç»¼åˆå»ºè®®
    report_lines.append("## ç»¼åˆå»ºè®®ä¸è¡ŒåŠ¨æ–¹æ¡ˆ\n")
    
    if results['error_analysis'] and results['valuation_analysis']:
        error_res = results['error_analysis']['detection_results']
        val_metrics = results['valuation_analysis']['value_metrics']
        
        # æ•°æ®æ¸…ç†å»ºè®®
        report_lines.append("### 1. æ•°æ®æ¸…ç†ç­–ç•¥\n")
        if error_res['num_suspicious'] > 0:
            suspicious_ratio = error_res['num_suspicious'] / len(error_res['usefulness_scores'])
            if suspicious_ratio > 0.1:
                report_lines.append("- âš ï¸ å¯ç–‘æ ·æœ¬æ¯”ä¾‹è¾ƒé«˜ï¼Œå»ºè®®ä¼˜å…ˆæ¸…ç†é”™è¯¯æ ‡ç­¾\n")
            else:
                report_lines.append("- âœ… å¯ç–‘æ ·æœ¬æ¯”ä¾‹è¾ƒä½ï¼Œæ•°æ®è´¨é‡è‰¯å¥½\n")
            
            report_lines.append(f"- ğŸ” æ‰‹åŠ¨æ£€æŸ¥æœ‰ç”¨æ€§åˆ†æ•°æœ€ä½çš„{min(100, error_res['num_suspicious'])}ä¸ªæ ·æœ¬\n")
        
        # æ•°æ®ä¼˜åŒ–å»ºè®®
        report_lines.append("\n### 2. æ•°æ®ä¼˜åŒ–ç­–ç•¥\n")
        high_value_threshold = val_metrics['l2_norm'].mean() + val_metrics['l2_norm'].std()
        high_value_count = sum(val_metrics['l2_norm'] >= high_value_threshold)
        low_value_threshold = val_metrics['l2_norm'].mean() - val_metrics['l2_norm'].std()
        low_value_count = sum(val_metrics['l2_norm'] <= low_value_threshold)
        
        report_lines.append(f"- ğŸ† ä¿æŠ¤é«˜ä»·å€¼æ ·æœ¬: {high_value_count}ä¸ªæ ·æœ¬ä»·å€¼è¶…è¿‡å‡å€¼+1Ïƒ\n")
        report_lines.append(f"- ğŸ“‰ è€ƒè™‘ç§»é™¤ä½ä»·å€¼æ ·æœ¬: {low_value_count}ä¸ªæ ·æœ¬ä»·å€¼ä½äºå‡å€¼-1Ïƒ\n")
        
        # è®­ç»ƒç­–ç•¥å»ºè®®
        report_lines.append("\n### 3. æ¨¡å‹è®­ç»ƒç­–ç•¥\n")
        if hasattr(val_metrics['l2_norm'], 'std'):
            value_cv = val_metrics['l2_norm'].std() / val_metrics['l2_norm'].mean()
            if value_cv > 0.5:
                report_lines.append("- ğŸ¯ ä»·å€¼åˆ†å¸ƒå·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨é‡è¦æ€§é‡‡æ ·\n")
                report_lines.append("- âš–ï¸ å¯¹é«˜ä»·å€¼æ ·æœ¬å¢åŠ æƒé‡æˆ–é‡å¤é‡‡æ ·\n")
            else:
                report_lines.append("- âœ… ä»·å€¼åˆ†å¸ƒç›¸å¯¹å‡åŒ€ï¼Œå¯ä½¿ç”¨æ ‡å‡†è®­ç»ƒç­–ç•¥\n")
    
    # åç»­åˆ†æå»ºè®®
    report_lines.append("\n### 4. åç»­åˆ†æå»ºè®®\n")
    report_lines.append("- ğŸ”„ å®šæœŸé‡æ–°è®¡ç®—Shapleyå€¼ï¼Œç›‘æ§æ•°æ®è´¨é‡å˜åŒ–\n")
    report_lines.append("- ğŸ“Š ç»“åˆæ¨¡å‹æ€§èƒ½æŒ‡æ ‡éªŒè¯æ•°æ®ä¼˜åŒ–æ•ˆæœ\n")
    report_lines.append("- ğŸ¨ è¿›è¡Œæ›´ç»†ç²’åº¦çš„ç‰¹å¾çº§åˆ«Shapleyåˆ†æ\n")
    report_lines.append("- ğŸ¤ ä¸é¢†åŸŸä¸“å®¶åˆä½œéªŒè¯æ£€æµ‹åˆ°çš„å¼‚å¸¸æ ·æœ¬\n")
    
    # æ–‡ä»¶è·¯å¾„ä¿¡æ¯
    if results['error_analysis']:
        report_lines.append(f"\n## è¯¦ç»†åˆ†æç»“æœ\n")
        report_lines.append(f"- é”™è¯¯æ£€æµ‹è¯¦ç»†ç»“æœ: {results['error_analysis']['save_dir']}\n")
    
    if results['valuation_analysis']:
        if 'error_analysis' not in locals():
            report_lines.append(f"\n## è¯¦ç»†åˆ†æç»“æœ\n")
        report_lines.append(f"- æ•°æ®ä¼°å€¼è¯¦ç»†ç»“æœ: {results['valuation_analysis']['save_dir']}\n")
    
    # ä¿å­˜ç»¼åˆæŠ¥å‘Š
    summary_path = os.path.join(save_dir, f'comprehensive_summary_{experiment_type}.md')
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.writelines(report_lines)
    
    return summary_path

def main():
    parser = argparse.ArgumentParser(description="Shapleyå€¼ç»¼åˆåˆ†æå·¥å…·")
    parser.add_argument("--type", choices=["resnet", "transformer"], 
                       default="resnet", help="å®éªŒç±»å‹")
    parser.add_argument("--analysis", choices=["error", "valuation", "comprehensive"],
                       default="comprehensive", help="åˆ†æç±»å‹")
    parser.add_argument("--error-threshold", type=float, default=5.0,
                       help="é”™è¯¯æ£€æµ‹é˜ˆå€¼ç™¾åˆ†ä½æ•° (default: 5.0)")
    parser.add_argument("--clusters", type=int, default=5,
                       help="èšç±»æ•°é‡ (default: 5)")
    
    args = parser.parse_args()
    
    if args.analysis == "error":
        print("ğŸ•µï¸ è¿è¡Œé”™è¯¯æ£€æµ‹åˆ†æ")
        run_error_analysis(args.type, args.error_threshold)
    elif args.analysis == "valuation":
        print("ğŸ’ è¿è¡Œæ•°æ®ä»·å€¼è¯„ä¼°")
        run_data_valuation(args.type, args.clusters)
    elif args.analysis == "comprehensive":
        print("ğŸ”¬ è¿è¡Œç»¼åˆåˆ†æ")
        run_comprehensive_analysis(args.type, args.error_threshold, args.clusters)
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()