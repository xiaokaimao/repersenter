#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•MMLUæ”¯æŒ
éªŒè¯æ•°æ®åŠ è½½å’ŒåŸºæœ¬åŠŸèƒ½
"""

import sys
sys.path.append('.')

def test_mmlu_loading():
    """æµ‹è¯•MMLUæ•°æ®åŠ è½½"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯•MMLUæ•°æ®åŠ è½½...")
    
    try:
        import utils
        
        # æµ‹è¯•MMLUæ•°æ®åŠ è½½
        train_loader, test_loader, _, _, num_classes, original_labels, flipped_indices = utils.get_text_data_loaders(
            dataset_name="mmlu",
            tokenizer_name="/opt/models/Qwen3-4B-Base",  # ä½¿ç”¨å½“å‰é…ç½®çš„æ¨¡å‹
            batch_size=4,  # å°æ‰¹æ¬¡æµ‹è¯•
            label_noise_rate=0.0
        )
        
        print(f"âœ… MMLUæ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
        print(f"  æµ‹è¯•æ ·æœ¬æ•°: {len(test_loader.dataset)}")
        print(f"  ç±»åˆ«æ•°: {num_classes}")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªbatch
        first_batch = next(iter(train_loader))
        print(f"  Batch shape: {first_batch['input_ids'].shape}")
        print(f"  Label range: {first_batch['labels'].min().item()} - {first_batch['labels'].max().item()}")
        
        # æ˜¾ç¤ºæ ·æœ¬ç¤ºä¾‹
        from transformers import AutoTokenizer
        tokenizer = AutoTokenizer.from_pretrained("/opt/models/Qwen3-4B-Base")
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            
        sample_text = tokenizer.decode(first_batch['input_ids'][0], skip_special_tokens=True)
        sample_label = first_batch['labels'][0].item()
        
        print(f"\nğŸ“ MMLUæ ·æœ¬ç¤ºä¾‹:")
        print(f"  æ–‡æœ¬: {sample_text[:300]}...")
        print(f"  æ ‡ç­¾: {sample_label} ({'ABCD'[sample_label]})")
        print(f"  æ–‡æœ¬é•¿åº¦: {len(sample_text)} å­—ç¬¦")
        
        return True
        
    except Exception as e:
        print(f"âŒ MMLUæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def compare_datasets():
    """æ¯”è¾ƒä¸‰ä¸ªæ•°æ®é›†çš„ç‰¹ç‚¹"""
    print("\nğŸ“Š æ•°æ®é›†å¯¹æ¯”:")
    print("=" * 60)
    
    datasets_info = {
        "IMDB": {
            "ç±»å‹": "æƒ…æ„Ÿåˆ†æ",
            "ç±»åˆ«æ•°": 2,
            "æ ¼å¼": "ç”µå½±è¯„è®ºæ–‡æœ¬ â†’ æ­£é¢/è´Ÿé¢",
            "åŸºå‡†å‡†ç¡®ç‡": "50% (éšæœº)",
            "ä»»åŠ¡éš¾åº¦": "ä¸­ç­‰"
        },
        "ARC-Challenge": {
            "ç±»å‹": "ç§‘å­¦æ¨ç†",
            "ç±»åˆ«æ•°": 4,
            "æ ¼å¼": "ç§‘å­¦é—®é¢˜+é€‰é¡¹ â†’ A/B/C/D",
            "åŸºå‡†å‡†ç¡®ç‡": "25% (éšæœº)",
            "ä»»åŠ¡éš¾åº¦": "å›°éš¾"
        },
        "MMLU": {
            "ç±»å‹": "ç»¼åˆçŸ¥è¯†",
            "ç±»åˆ«æ•°": 4,
            "æ ¼å¼": "57å­¦ç§‘é—®é¢˜+é€‰é¡¹ â†’ A/B/C/D",
            "åŸºå‡†å‡†ç¡®ç‡": "25% (éšæœº)",
            "ä»»åŠ¡éš¾åº¦": "éå¸¸å›°éš¾"
        }
    }
    
    for dataset, info in datasets_info.items():
        print(f"\nğŸ¯ {dataset}:")
        for key, value in info.items():
            print(f"   {key}: {value}")

def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨æ–¹æ³•"""
    print("\nğŸš€ ä½¿ç”¨æ–¹æ³•:")
    print("=" * 50)
    
    print("\n1ï¸âƒ£ åˆ‡æ¢åˆ°MMLU:")
    print("   python switch_to_arc.py mmlu")
    
    print("\n2ï¸âƒ£ è®­ç»ƒMMLUæ¨¡å‹:")
    print("   python experiments/transformer/finetune.py")
    
    print("\n3ï¸âƒ£ è®¡ç®—Shapleyå€¼:")
    print("   python experiments/transformer/run_shapley.py")
    
    print("\n4ï¸âƒ£ åˆ†ææ•°æ®è´¨é‡:")
    print("   python experiments/analysis/run_analysis.py --type transformer")
    
    print("\nğŸ’¡ æç¤º:")
    print("   - MMLUæœ‰57ä¸ªå­¦ç§‘ï¼Œæ•°æ®é‡è¾ƒå¤§")
    print("   - å»ºè®®ä½¿ç”¨è¾ƒå°çš„batch size (32)")
    print("   - æ¨ç†ä»»åŠ¡å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒè½®æ•°")
    print("   - Shapleyåˆ†æå¯ä»¥æ­ç¤ºæ¨¡å‹ä¾èµ–çš„çŸ¥è¯†ç±»å‹")

if __name__ == "__main__":
    print("ğŸ§  MMLU (Massive Multitask Language Understanding) æ”¯æŒæµ‹è¯•")
    print("=" * 70)
    
    # æ¯”è¾ƒæ•°æ®é›†
    compare_datasets()
    
    # æµ‹è¯•MMLUåŠ è½½
    success = test_mmlu_loading()
    
    if success:
        print("\nâœ… MMLUæ”¯æŒæµ‹è¯•æˆåŠŸ!")
        show_usage()
        
        print("\nğŸŠ ç°åœ¨ä½ çš„é¡¹ç›®æ”¯æŒä¸‰ç§ç±»å‹çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡:")
        print("   ğŸ“º IMDB - æƒ…æ„Ÿåˆ†æ")
        print("   ğŸ§ª ARC-Challenge - ç§‘å­¦æ¨ç†") 
        print("   ğŸ“ MMLU - ç»¼åˆçŸ¥è¯†è¯„ä¼°")
        print("\nå®Œå…¨ä½¿ç”¨åŒä¸€å¥—ä»£ç ï¼Œåªéœ€è¦åˆ‡æ¢æ•°æ®é›†é…ç½®ï¼")
    else:
        print("\nâŒ MMLUæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä¾èµ–ç¯å¢ƒ")
        print("éœ€è¦ç¡®ä¿èƒ½è®¿é—®HuggingFaceæ•°æ®é›†")